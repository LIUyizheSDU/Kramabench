{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in /opt/homebrew/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/homebrew/lib/python3.11/site-packages (from geopy) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: kagglehub in /opt/homebrew/lib/python3.11/site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from kagglehub) (23.1)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/lib/python3.11/site-packages (from kagglehub) (6.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from kagglehub) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->kagglehub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->kagglehub) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->kagglehub) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install geopy\n",
    "%pip install kagglehub\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "from geopy import distance\n",
    "from scipy.stats import zscore\n",
    "\n",
    "nifc_data = pd.read_csv('nifc_wildfires.csv', delimiter='\\t')\n",
    "noaa_data = pd.read_csv('noaa_wildfires.csv', skiprows=3)\n",
    "nifc_human_acres = pd.read_csv('nifc_human_caused_acres.csv', delimiter='\\t')\n",
    "nifc_lightning_acres = pd.read_csv('nifc_lightning_caused_acres.csv', delimiter='\\t')\n",
    "wildfire_noaa_data = pd.read_csv('noaa_wildfires_sylvia.csv')\n",
    "\n",
    "path = kagglehub.dataset_download(\"sobhanmoosavi/us-weather-events\")\n",
    "weather_events = pd.read_csv(path + '/WeatherEvents_Jan2016-Dec2022.csv')\n",
    "path_2 = kagglehub.dataset_download(\"robikscube/zillow-home-value-index\")\n",
    "zhvi = pd.read_csv(path_2 + '/ZHVI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c34a9",
   "metadata": {},
   "source": [
    "# `wildfire-hard-5`: On average, how many more annual fires are reported by NOAA compared to NIFC since 2000? Round to the nearest whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90ce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_data['Datetime'] = pd.to_datetime(noaa_data['Date'], format='%Y%m')\n",
    "noaa_data['Year'] = noaa_data['Datetime'].dt.year\n",
    "noaa_data['Month'] = noaa_data['Datetime'].dt.month\n",
    "noaa_yearly_data = noaa_data.groupby(['Year']).agg({'Number of Fires': 'sum', 'Acres Burned': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3aae9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1039"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an inner join on the 'Year' column\n",
    "merged_data = pd.merge(\n",
    "    nifc_data.rename(columns={'Fires': 'NIFC_Fires', 'Acres': 'NIFC_Acres'}),\n",
    "    noaa_yearly_data.rename(columns={'Number of Fires': 'NOAA_Number_of_Fires', 'Acres Burned': 'NOAA_Acres_Burned'}),\n",
    "    on='Year',\n",
    "    how='inner'\n",
    ")\n",
    "merged_data['Difference_in_Fires'] = merged_data['NOAA_Number_of_Fires'] - merged_data['NIFC_Fires'].str.replace(',', '').astype(int)\n",
    "round(merged_data['Difference_in_Fires'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00e02b",
   "metadata": {},
   "source": [
    "# `wildfire-hard-6`: What is the correlation between (1) the difference between the number of NOAA and NIFC-reported fires and (2) the difference between the acres burned by NOAA and NIFC-reported fires, on an annual basis?\n",
    "Comment: Make sure to mention we need to round to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872f95be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/1941409489.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  merged_data['Difference_in_Acres'] = merged_data['NOAA_Acres_Burned'] - merged_data['NIFC_Acres'].str.replace(',', '').str.replace('*', '').astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.519"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['Difference_in_Acres'] = merged_data['NOAA_Acres_Burned'] - merged_data['NIFC_Acres'].str.replace(',', '').str.replace('*', '').astype(int)\n",
    "round(merged_data['Difference_in_Fires'].corr(merged_data['Difference_in_Acres']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28326c39",
   "metadata": {},
   "source": [
    "# `wildfire-hard-7`: Which geographic area had the most anomalous year (by Z-score) in terms of total acres burned compared to its historical annual average, and what year was it in?\n",
    "Comment: The answer is different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9c03ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3805387751.py:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  nifc_human_acres.iloc[:, 1:] = nifc_human_acres.iloc[:, 1:].replace({',': ''}, regex=True).astype(float).astype('Int64')\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3805387751.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  nifc_lightning_acres.iloc[:, 1:] = nifc_lightning_acres.iloc[:, 1:].replace({',': ''}, regex=True).astype(float).astype('Int64')\n"
     ]
    }
   ],
   "source": [
    "nifc_lightning_acres.rename(columns={'Western Great Basin*': 'Western Great Basin'}, inplace=True)\n",
    "nifc_human_acres.iloc[:, 1:] = nifc_human_acres.iloc[:, 1:].replace({',': ''}, regex=True).astype(float).astype('Int64')\n",
    "nifc_lightning_acres.iloc[:, 1:] = nifc_lightning_acres.iloc[:, 1:].replace({',': ''}, regex=True).astype(float).astype('Int64')\n",
    "combined_acres = pd.merge(nifc_human_acres, nifc_lightning_acres, on='Year', suffixes=('_human', '_lightning'))\n",
    "\n",
    "regions = nifc_human_acres.columns[1:]\n",
    "for region in regions:\n",
    "    combined_acres[region] = combined_acres[f\"{region}_human\"] + combined_acres[f\"{region}_lightning\"]\n",
    "combined_acres.drop(columns=[f\"{region}_human\" for region in regions] + [f\"{region}_lightning\" for region in regions], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c0fc5a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "z_scores = combined_acres.copy()\n",
    "for region in regions:\n",
    "    z_scores[region] = zscore(combined_acres[region].fillna(0).astype(int), nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce85f57c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Z-score: 3.9498889601744533 in Northwest for year 2020\n"
     ]
    }
   ],
   "source": [
    "max_value = z_scores[regions].to_numpy().max()\n",
    "row, col = np.where(z_scores[regions].to_numpy() == max_value)\n",
    "region = regions[col[0]]\n",
    "year = z_scores.iloc[row]['Year'].values[0]\n",
    "print(f\"Max Z-score: {max_value} in {region} for year {year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696969b",
   "metadata": {},
   "source": [
    "# `wildfire-15`: In 2016, what percentage of fires were brought under control with it raining moderately or heavily (>0.05 in) in the fire area on the same or previous day? Give an upper bound assuming that the narrowest diameter of the fire region is 1km.\n",
    "Comment: I'd like clarification that 'on the same or previous day' refers to the day the fire was controlled. Perhaps 'on or a day before the control day' could do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a27a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first filter is for types of precipitation, the year filter needs to come after splitting out UTC times, and the fire area / timing needs to come after the fire dataset is processed\n",
    "mask =  (weather_events['Precipitation(in)'] > 0.05) & (\n",
    "            (weather_events['Type'] == 'Precipitation') |\n",
    "            (weather_events['Type'] == 'Rain') # | weather_events['Type'] == 'Storm') # according to the paper, storm means strong winds\n",
    "        ) & (\n",
    "            (weather_events['Severity'] == 'Moderate') |\n",
    "            (weather_events['Severity'] == 'Heavy') |\n",
    "            (weather_events['Severity'] == 'Severe')\n",
    "        )\n",
    "initial_filter_weather_events = weather_events[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15971b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['StartTime(Local)'] = initial_filter_weather_events.apply(\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['EndTime(Local)'] = initial_filter_weather_events.apply(\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['StartDay(Local)'] = initial_filter_weather_events['StartTime(Local)'].apply(lambda x: x.day)\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['EndDay(Local)'] = initial_filter_weather_events['EndTime(Local)'].apply(lambda x: x.day)\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['StartDayOfYear(Local)'] = initial_filter_weather_events['StartTime(Local)'].apply(lambda x: x.timetuple().tm_yday)\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['EndDayOfYear(Local)'] = initial_filter_weather_events['EndTime(Local)'].apply(lambda x: x.timetuple().tm_yday)\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['StartYear(Local)'] = initial_filter_weather_events['StartTime(Local)'].apply(lambda x: x.year)\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['EndYear(Local)'] = initial_filter_weather_events['EndTime(Local)'].apply(lambda x: x.year)\n",
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3039365494.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_weather_events['SameYear'] = initial_filter_weather_events['StartYear(Local)'] == initial_filter_weather_events['EndYear(Local)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartYear(Local)</th>\n",
       "      <th>EndYear(Local)</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2021</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StartYear(Local)  EndYear(Local)  Counts\n",
       "0              2016            2017      23\n",
       "1              2018            2019      54\n",
       "2              2019            2020       2\n",
       "3              2020            2021      45\n",
       "4              2021            2022      16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert UTC start and end times to local time zone\n",
    "def convert_to_local_time(utc_time, time_zone):\n",
    "    utc_datetime = datetime.strptime(utc_time, '%Y-%m-%d %H:%M:%S')\n",
    "    tz = pytz.timezone(time_zone)\n",
    "    return tz.normalize(pytz.utc.localize(utc_datetime).astimezone(tz))\n",
    "# convert_to_local_time('2016-02-01 08:15:00', 'US/Mountain').date()\n",
    "\n",
    "initial_filter_weather_events['StartTime(Local)'] = initial_filter_weather_events.apply(\n",
    "    lambda row: convert_to_local_time(row['StartTime(UTC)'], row['TimeZone']), axis=1\n",
    ")\n",
    "initial_filter_weather_events['EndTime(Local)'] = initial_filter_weather_events.apply(\n",
    "    lambda row: convert_to_local_time(row['EndTime(UTC)'], row['TimeZone']), axis=1\n",
    ")\n",
    "\n",
    "initial_filter_weather_events['StartDay(Local)'] = initial_filter_weather_events['StartTime(Local)'].apply(lambda x: x.day)\n",
    "initial_filter_weather_events['EndDay(Local)'] = initial_filter_weather_events['EndTime(Local)'].apply(lambda x: x.day)\n",
    "\n",
    "initial_filter_weather_events['StartDayOfYear(Local)'] = initial_filter_weather_events['StartTime(Local)'].apply(lambda x: x.timetuple().tm_yday)\n",
    "initial_filter_weather_events['EndDayOfYear(Local)'] = initial_filter_weather_events['EndTime(Local)'].apply(lambda x: x.timetuple().tm_yday)\n",
    "\n",
    "initial_filter_weather_events['StartYear(Local)'] = initial_filter_weather_events['StartTime(Local)'].apply(lambda x: x.year)\n",
    "initial_filter_weather_events['EndYear(Local)'] = initial_filter_weather_events['EndTime(Local)'].apply(lambda x: x.year)\n",
    "initial_filter_weather_events['SameYear'] = initial_filter_weather_events['StartYear(Local)'] == initial_filter_weather_events['EndYear(Local)']\n",
    "\n",
    "# seems like there are actually some weather events that start and end in different years, wonder if they will stay around after we join with fire incidents; seems safe to filter by start year\n",
    "initial_filter_weather_events[initial_filter_weather_events['SameYear'] == False].groupby(['StartYear(Local)', 'EndYear(Local)']).size().reset_index(name='Counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d95f0d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_year</th>\n",
       "      <th>control_year</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>2006</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>2010</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_year  control_year  Counts\n",
       "0         2002          2002     403\n",
       "1         2003          2003     465\n",
       "2         2004          2004     273\n",
       "3         2005          2005     515\n",
       "4         2006          2006     817\n",
       "5         2007          2007     600\n",
       "6         2008          2008     473\n",
       "7         2009          2009     419\n",
       "8         2010          2010     333\n",
       "9         2011          2011     565\n",
       "10        2012          2012     648\n",
       "11        2013          2013     398\n",
       "12        2014          2014     270\n",
       "13        2016          2016     479"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_weather_events = initial_filter_weather_events[initial_filter_weather_events['StartYear(Local)'] == 2016]\n",
    "\n",
    "# meanwhile, it seems like the noaa data does not have 2016 fires that cross into 2015 or 2017\n",
    "wildfire_noaa_data.groupby(['start_year', 'control_year']).size().reset_index(name='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9a8010",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3785908159.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_fires['upper_bound_fire_radius_km'] = initial_filter_fires.apply(\n"
     ]
    }
   ],
   "source": [
    "initial_filter_fires = wildfire_noaa_data[(wildfire_noaa_data['start_year'] == 2016)]\n",
    "def find_fire_radius(latitude, longitude, hectares):\n",
    "    area = hectares / 100\n",
    "    a = area / 1 # assuming minimum diameter of 1km\n",
    "    return max(a, 0.5)  # min radius of 0.5km\n",
    "\n",
    "initial_filter_fires['upper_bound_fire_radius_km'] = initial_filter_fires.apply(\n",
    "    lambda row: find_fire_radius(row['latitude'], row['longitude'], row['hec']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c08385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3640368283.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_filter_fires['OverlappingWeatherEvents'] = initial_filter_fires.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverlappingWeatherEvents</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverlappingWeatherEvents  Counts\n",
       "0                     False     472\n",
       "1                      True       7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter weather events that overlap with the control day or the day before the control day of the fire\n",
    "def find_overlapping_weather_events(fire_row, weather_events):\n",
    "    control_day = fire_row.get('control_day_of_year')\n",
    "    control_year = fire_row.get('control_year')\n",
    "    fitting_weather_events = weather_events[\n",
    "        (weather_events['StartDayOfYear(Local)'] <= control_day) &\n",
    "        (weather_events['EndDayOfYear(Local)'] >= control_day - 1) &\n",
    "        (weather_events['StartYear(Local)'] == control_year)\n",
    "    ]\n",
    "\n",
    "    fire_lat, fire_long, fire_radius_km = fire_row.get('latitude'), fire_row.get('longitude'), fire_row.get('upper_bound_fire_radius_km')\n",
    "\n",
    "    if fitting_weather_events.empty:\n",
    "        return False\n",
    "\n",
    "    closest_weather_event_distance = float('inf')\n",
    "\n",
    "    for _, weather_event in fitting_weather_events.iterrows():\n",
    "        weather_lat, weather_long = weather_event['LocationLat'], weather_event['LocationLng']\n",
    "\n",
    "        # haversine formula to convert lat/long to km\n",
    "        # https://en.wikipedia.org/wiki/Haversine_formula\n",
    "        R = 6371.001 # arithmetic mean of the earth's radius in km https://en.wikipedia.org/wiki/Earth_radius\n",
    "        lat1, long1, lat2, long2 = map(np.radians, [fire_lat, fire_long, weather_lat, weather_long])\n",
    "        d_lat = lat2 - lat1\n",
    "        d_lon = long2 - long1\n",
    "        weather_distance = 2 * R * np.arcsin(np.sqrt((np.sin(d_lat / 2) ** 2) + np.cos(lat1) * np.cos(lat2) * (np.sin(d_lon / 2) ** 2)))\n",
    "        # a = np.sin(d_lat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(d_lon / 2)**2\n",
    "        # c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "        # weather_distance = R * c\n",
    "        # weather_distance = distance.distance((fire_lat, fire_long), (weather_lat, weather_long)).km\n",
    "\n",
    "        if weather_distance < closest_weather_event_distance:\n",
    "            closest_weather_event_distance = weather_distance\n",
    "    \n",
    "    if closest_weather_event_distance > fire_radius_km:\n",
    "        return False\n",
    "    else:\n",
    "        return closest_weather_event_distance <= fire_radius_km\n",
    "\n",
    "initial_filter_fires['OverlappingWeatherEvents'] = initial_filter_fires.apply(\n",
    "    lambda row: find_overlapping_weather_events(row, filtered_weather_events), axis=1\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "initial_filter_fires.groupby(['OverlappingWeatherEvents']).size().reset_index(name='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005ad3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4613778705636742%\n"
     ]
    }
   ],
   "source": [
    "print(str(initial_filter_fires['OverlappingWeatherEvents'].mean() * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db780326",
   "metadata": {},
   "source": [
    "# `wildfire-16`: According to NOAA, what percentage of wildfires account for 90% of residential houses damaged in 2008?\n",
    "Comment: Unless we want exactly 90%, so I would suggest rephrasing for 'smallest percentage' and 'at least 90% of'. Otherwise, rounding could save us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865cfd4c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "yearly_wildfire_noaa = wildfire_noaa_data.groupby('start_year').agg({\n",
    "    'prim_threatened_aggregate': 'sum'\n",
    "}).reset_index()\n",
    "residential_proportion_threshold = yearly_wildfire_noaa[yearly_wildfire_noaa['start_year'] == 2008]['prim_threatened_aggregate'].sum() * 0.9\n",
    "total_count = len(wildfire_noaa_data[wildfire_noaa_data['start_year'] == 2008])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a41000",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4397% of fires'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires_sorted_by_prim_threat = wildfire_noaa_data[wildfire_noaa_data['start_year'] == 2008].sort_values(by='prim_threatened_aggregate', ascending=False)['prim_threatened_aggregate']\n",
    "\n",
    "# smallest number of fires to cross the threshold, when sorted from most damaging to least\n",
    "cumulative_sum = 0\n",
    "cumulative_count = 0\n",
    "for fire in fires_sorted_by_prim_threat:\n",
    "    cumulative_sum += fire\n",
    "    cumulative_count += 1\n",
    "    if int(cumulative_sum + fire) >= int(residential_proportion_threshold):\n",
    "        break\n",
    "    \n",
    "str(round(cumulative_count / total_count * 100, 4)) + \"% of fires\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f29779",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.6512% of fires'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of fires exactly needed to cross the threshold\n",
    "cumulative_sum = 0\n",
    "cumulative_count = 0\n",
    "for fire in fires_sorted_by_prim_threat:\n",
    "    if int(cumulative_sum + fire) == int(residential_proportion_threshold):\n",
    "        break\n",
    "    if int(cumulative_sum + fire) > int(residential_proportion_threshold):\n",
    "        continue\n",
    "    cumulative_sum += fire\n",
    "    cumulative_count += 1\n",
    "\n",
    "str(round(cumulative_count / total_count * 100, 4)) + \"% of fires\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c99fb1",
   "metadata": {},
   "source": [
    "# `wildfire-17`: Based on NOAA data, what are the top 3 states that lost the most residential property in value between 2005 and 2010 (including 2005 and 2010)? Answer in state full names.\n",
    "Comment: The estimated residential value of each house impacted by a fire can vary depending on how we choose the month of the relevant average residential value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b8177f4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhvi['Datetime'] = pd.to_datetime(zhvi['Unnamed: 0'])\n",
    "zhvi['Year'] = zhvi['Datetime'].dt.year\n",
    "zhvi['Month'] = zhvi['Datetime'].dt.month\n",
    "zhvi.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "state_name_to_abbreviation = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\", \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\", \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\", \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\",\n",
    "    \"the District of Columbia\": \"DC\",\n",
    "}\n",
    "abbreviation_to_state_name = {}\n",
    "for state, abbreviation in state_name_to_abbreviation.items():\n",
    "    abbreviation_to_state_name[abbreviation] = state\n",
    "\n",
    "wildfire_noaa_data['start_month'] = pd.to_datetime(wildfire_noaa_data['start_date']).dt.month\n",
    "wildfire_noaa_data['control_month'] = pd.to_datetime(wildfire_noaa_data['controlled_date']).dt.month\n",
    "noaa_data_masked = wildfire_noaa_data[(wildfire_noaa_data['start_year'] >= 2005) & (wildfire_noaa_data['start_year'] <= 2010)] # there are no wildfires that span multiple years so this is safe\n",
    "# seems like there's multiple fires that span the same month though\n",
    "len(noaa_data_masked[noaa_data_masked['start_month'] != noaa_data_masked['control_month']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af45a17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fortunately there's no missing values to worry about in this time range\n",
    "noaa_data_masked['start_date'].isna().sum(), noaa_data_masked['controlled_date'].isna().sum(), noaa_data_masked['state'].isna().sum(), noaa_data_masked['prim_threatened_aggregate'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d795f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800976.697397812\n"
     ]
    }
   ],
   "source": [
    "# for each fire listed in noaa data masked, get the weighted home value for the duration of the fire, making the assumption that the value could be realized at any point in the fire duration if the fire didn't happen\n",
    "def get_weighted_residential_value_for_fire(start_date, end_date, state, prim_threatened_aggregate): # can guarantee fields are populated\n",
    "    # Get the start and end dates of the fire\n",
    "    dt_start_date = pd.to_datetime(start_date)\n",
    "    dt_end_date = pd.to_datetime(end_date)\n",
    "    start_year = dt_start_date.year\n",
    "    start_month = dt_start_date.month\n",
    "    # get number of days in each month between start and end date\n",
    "    num_days_per_month = pd.date_range(start=dt_start_date, end=dt_end_date, freq='M').day\n",
    "    num_days_total = (dt_end_date - dt_start_date).days + 1\n",
    "    if num_days_per_month.empty: # if the fire does not span multiple months\n",
    "        num_days_per_month = [num_days_total]\n",
    "    # get the zillow home value per month for the state\n",
    "    home_value_per_month = [\n",
    "        zhvi.loc[(zhvi['Year'] == start_year) & (zhvi['Month'] == start_month + i), state].values[0]\n",
    "        if not zhvi.loc[(zhvi['Year'] == start_year) & (zhvi['Month'] == start_month + i), state].empty else None\n",
    "        for i in range(len(num_days_per_month))\n",
    "    ]\n",
    "    total_weighted_value = sum([value * days for value, days in zip(home_value_per_month, num_days_per_month) if not pd.isna(value)])\n",
    "    weighted_home_value_during_fire = total_weighted_value / num_days_total\n",
    "    total_impacted_home_value_estimate = weighted_home_value_during_fire * prim_threatened_aggregate\n",
    "    return total_impacted_home_value_estimate\n",
    "    \n",
    "print(get_weighted_residential_value_for_fire('8/27/2005', '8/29/2005', 'California', 15)) # test on the first fire entry in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6e94234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/lv8dl5zj78n8fw343s4t1jmc0000gn/T/ipykernel_70624/3749176147.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noaa_data_masked['weighted_home_value_during_fire'] = noaa_data_masked.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>weighted_home_value_during_fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>3.811669e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>2.954208e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WA</td>\n",
       "      <td>2.361739e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  weighted_home_value_during_fire\n",
       "1    CA                     3.811669e+11\n",
       "3    ID                     2.954208e+10\n",
       "9    WA                     2.361739e+10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaa_data_masked['weighted_home_value_during_fire'] = noaa_data_masked.apply(\n",
    "    lambda row: get_weighted_residential_value_for_fire(\n",
    "        row['start_date'],\n",
    "        row['controlled_date'],\n",
    "        abbreviation_to_state_name[row['state']],\n",
    "        row['prim_threatened_aggregate']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "states_ordered_by_devastation = noaa_data_masked.groupby('state').agg({'weighted_home_value_during_fire': 'sum'}).reset_index().sort_values(by='weighted_home_value_during_fire', ascending=False)\n",
    "states_ordered_by_devastation[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
